# üß† COMPSCI 589 Final Project ‚Äì Spring 2025

This repository contains custom implementations of core machine learning algorithms and their application across a variety of datasets. Developed as the final project for COMPSCI 589 at UMass Amherst.

> üë• **Team Members**  
> ‚Ä¢ Kartikay Gupta ‚Äì Implemented Decision Tree, Random Forest, Naive Bayes  
> ‚Ä¢ Jeffrey Deng ‚Äì Implemented Neural Network (MLP with backpropagation)

---

## üéØ Project Goals

- Apply and compare original implementations of key ML algorithms
- Analyze algorithm behavior using **10-fold stratified cross-validation**
- Explore hyperparameter tuning and visualize results via matplotlib
- **No use of high-level ML libraries** like scikit-learn for modeling

---

## üìä Datasets Used

| Dataset            | Classes | Features | Type                            |
|--------------------|---------|----------|---------------------------------|
| Digits (Sklearn)   | 10      | 64       | Image classification            |
| Parkinson‚Äôs        | 2       | 22       | Biomedical voice data           |
| Rice Grain         | 2       | 7        | Morphological image features    |
| Credit Approval    | 2       | 15       | Mixed categorical + numerical   |
| Fertilizer (Kaggle)| 10      | Mixed    | Soil/crop conditions (Extra)    |

---

## üß† Algorithms Implemented

| Algorithm        | Contributor     | Notes                                        |
|------------------|------------------|----------------------------------------------|
| Decision Tree    | Kartikay Gupta   | From-scratch, entropy/Gini split, label encoded |
| Random Forest    | Kartikay Gupta   | Ensemble with bootstrap and aggregation      |
| Naive Bayes      | Kartikay Gupta   | Multiclass support, tuned smoothing factor Œ± |
| Neural Network   | Jeffrey Deng     | Multilayer Perceptron with backpropagation   |

---

## üìà Performance Summary

| Algorithm        | Digits (Acc/F1) | Parkinson (Acc/F1) | Rice (Acc/F1) | Credit (Acc/F1) | Fertilizer (Acc/F1) |
|------------------|------------------|----------------------|----------------|------------------|----------------------|
| Decision Tree    | 0.8202 / 0.8198 | 0.8770 / 0.8152     | 0.9213 / 0.9192| 0.8133 / 0.8100 | 0.9861 / 0.9493     |
| Random Forest    | 0.8812 / 0.8797 | 0.8253 / 0.7855     | 0.9055 / 0.9033| 0.8149 / 0.8121 | ‚Äî / ‚Äî               |
| Naive Bayes      | ‚Äî / ‚Äî           | ‚Äî / ‚Äî               | ‚Äî / ‚Äî         | ‚Äî / ‚Äî           | 1.0000 / 1.0000     |
| Neural Network   | 0.9806 / 0.9803 | 0.8974 / 0.8427     | 0.9449 / 0.9436| 0.9160 / 0.9157 | ‚Äî / ‚Äî               |

‚úîÔ∏è **Highlights**:  
- Neural Networks outperformed all others in **Digits, Parkinson‚Äôs, Rice, and Credit** datasets.  
- Naive Bayes achieved **perfect scores** on the Fertilizer dataset.  
- Decision Trees showed consistently strong and interpretable results across datasets.

---

## üìÇ Project Structure

‚îú‚îÄ‚îÄ code/ # All algorithm implementations (no scikit-learn models used)

--
‚îú‚îÄ‚îÄ data/ # Datasets in CSV format

--
‚îú‚îÄ‚îÄ results/ # Output plots, performance tables

--
‚îú‚îÄ‚îÄ Final_Report.pdf # Official final submission with figures and write-up

--
‚îî‚îÄ‚îÄ README.md # This file
--

---

## üèÜ Extra Credit

- ‚úÖ Used 3+ algorithms for multiple datasets  
- ‚úÖ Included a **challenging multiclass + mixed-type dataset**  
- ‚úÖ Perfect score (1.000) achieved using Naive Bayes on Fertilizer data

---

## üßë‚Äçüíª Authors

- **Kartikay Gupta**  
  üìß kartikaygupt@umass.edu  
  üîó [LinkedIn](https://linkedin.com/in/kartikay77)

- **Jeffrey Deng**  
  üìß jjdeng@umass.edu

---

> ‚ö†Ô∏è Models in this repo are implemented fully from scratch per course policy. Neural Network implementation and performance analysis credited to Jeffrey Deng.


